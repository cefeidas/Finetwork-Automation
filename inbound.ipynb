{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inbound Notebook\n",
    "\n",
    "This notebook is designed to semi-automate the reporting process for the Inbound team. It will streamline data extraction, transformation, and loading into a pre-formatted Excel file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Preparation\n",
    "\n",
    "The first step involves manually preparing the data in Excel:\n",
    "\n",
    "1. **Filter the Pivot Table:**\n",
    "   - Apply filters to the pivot table to extract the following categories:\n",
    "     - Active\n",
    "     - Canceled\n",
    "     - Pending Signature\n",
    "     - Net\n",
    "\n",
    "2. **Create Separate Sheets:**\n",
    "   - For each category (Active, Canceled, Pending Signature, Net), create a separate sheet in the Excel file containing the filtered data.\n",
    "\n",
    "3. **Save the Excel File:**\n",
    "   - Save the prepared Excel file with a specific name, ensuring it contains the sheets with the filtered data.\n",
    "\n",
    "4. **Upload the Excel File:**\n",
    "   - Upload the prepared Excel file to the designated directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Installation\n",
    "\n",
    "Ensure that the necessary libraries are installed before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "%pip install openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "print(\"Skeleton setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Declaration\n",
    "\n",
    "Set the variables for file paths, sheet names, and other configurations. Update these variables for each specific project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the Excel file (change this for each project)\n",
    "excel_file_path = '/workspaces/Finetwork-Automation/inbound/Metabase.xlsx'\n",
    "csv_file_path = '/workspaces/Finetwork-Automation/inbound/Informe de métricas históricas.csv'\n",
    "\n",
    "# Sheet names for different categories\n",
    "sheet_active = 'ACTIVOS'\n",
    "sheet_canceled = 'CANCELADOS'\n",
    "sheet_pending = 'PTE DE FIRMA'\n",
    "\n",
    "# Range to read (change this for each project)\n",
    "start_row = 8\n",
    "end_row = 65\n",
    "usecols = 'A:AF'\n",
    "\n",
    "print(\"Variables defined correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from \"Informe de métricas históricas\" CSV file\n",
    "Extract data from the CSV file and convert it directly to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "pivot_df = df.pivot_table(index=['Agent', 'StartInterval', 'EndInterval'], \n",
    "                          values=['Contacts handled incoming', 'Contacts transferred out internal'], \n",
    "                          aggfunc='first') \n",
    "\n",
    "\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from 'Active' Sheet\n",
    "\n",
    "Extract data from the \"Active\" sheet within the specified range and convert it directly to a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Columns in 'Active' Sheet\n",
    "\n",
    "Verify the number of columns in the \"Active\" sheet to ensure the range is within bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to verify the number of columns\n",
    "def verify_columns(file_path, sheet_name):\n",
    "    workbook = load_workbook(filename=file_path, data_only=True)\n",
    "    sheet = workbook[sheet_name]\n",
    "    max_column = sheet.max_column\n",
    "    return max_column\n",
    "\n",
    "# Check the number of columns in the 'Active' sheet\n",
    "max_column_active = verify_columns(excel_file_path, 'ACTIVOS')\n",
    "print(f\"Max column in 'Active' sheet: {max_column_active}\")\n",
    "\n",
    "# Check if the number of columns matches the expected range\n",
    "expected_columns = 32  # Columns from A to AF (inclusive)\n",
    "if max_column_active < expected_columns:\n",
    "    usecols = f\"A:{chr(64+max_column_active)}\"\n",
    "    print(f\"Adjusted usecols to: {usecols}\")\n",
    "else:\n",
    "    print(f\"Using default usecols: {usecols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from 'Active' Sheet\n",
    "\n",
    "Extract data from the \"Active\" sheet within the specified range and convert it directly to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sheet_as_dataframe(file_path, sheet_name, start_row, end_row, usecols):\n",
    "    # Load data from the specified sheet and range into a DataFrame\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, usecols=usecols, skiprows=start_row-1, nrows=end_row-start_row+1)\n",
    "    print(f\"Data from '{sheet_name}' sheet loaded successfully.\")\n",
    "    return df\n",
    "\n",
    "# Extract data from 'Active' sheet\n",
    "active_df = load_sheet_as_dataframe(excel_file_path, 'ACTIVOS', start_row, end_row, usecols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from 'Canceled' Sheet\n",
    "\n",
    "Extract data from the \"Canceled\" sheet within the specified range and convert it directly to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from 'Canceled' sheet\n",
    "canceled_df = load_sheet_as_dataframe(excel_file_path, 'CANCELADOS', start_row, end_row, usecols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from 'Pending Signature' Sheet\n",
    "\n",
    "Extract data from the \"Pending Signature\" sheet within the specified range and convert it directly to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from 'Pending Signature' sheet\n",
    "pending_signature_df = load_sheet_as_dataframe(excel_file_path, 'PTE FIRMA', start_row, end_row, usecols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display DataFrames\n",
    "\n",
    "Display the first few rows of each DataFrame to verify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrames\n",
    "print(\"Active DataFrame:\")\n",
    "display(active_df.head())\n",
    "\n",
    "print(\"Canceled DataFrame:\")\n",
    "display(canceled_df.head())\n",
    "\n",
    "print(\"Pending Signature DataFrame:\")\n",
    "display(pending_signature_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace NaN with 0\n",
    "\n",
    "Replace all NaN values in the DataFrames with 0 to facilitate further transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_with_zero(df):\n",
    "    \"\"\"\n",
    "    Replace all NaN values in the DataFrame with 0.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to process.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The processed DataFrame with NaN replaced by 0.\n",
    "    \"\"\"\n",
    "    df = df.fillna(0)\n",
    "    print(\"Replaced NaN with 0.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Transformation\n",
    "\n",
    "Apply the transformation to replace NaN values with 0 in each DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation\n",
    "active_df = replace_nan_with_zero(active_df)\n",
    "canceled_df = replace_nan_with_zero(canceled_df)\n",
    "pending_signature_df = replace_nan_with_zero(pending_signature_df)\n",
    "\n",
    "# Display the transformed DataFrames\n",
    "print(\"Active DataFrame after replacing NaN:\")\n",
    "display(active_df.head())\n",
    "\n",
    "print(\"Canceled DataFrame after replacing NaN:\")\n",
    "display(canceled_df.head())\n",
    "\n",
    "print(\"Pending Signature DataFrame after replacing NaN:\")\n",
    "display(pending_signature_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Agents List\n",
    "\n",
    "Load the list of all agents from the \"Agents\" sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of agents\n",
    "agents_df = pd.read_excel(excel_file_path, sheet_name='AGENTES', usecols='A')\n",
    "agents_list = agents_df.iloc[:, 0].tolist()\n",
    "print(\"Agents list loaded successfully!\")\n",
    "print(agents_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorganize and Group Data in Informe.csv\n",
    "\n",
    "Transform the CSV data into a more structured format by pivoting the DataFrame. This step groups the data by agent and date, allowing for easy access to each agent's daily call statistics. The resulting structure organizes call data by date for each agent, creating a clear and manageable dataset for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el CSV en un DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Crear una tabla pivote que agrupe por 'Agent', 'StartInterval', 'EndInterval'\n",
    "pivot_df = df.pivot_table(index=['Agent', 'StartInterval', 'EndInterval'], \n",
    "                          values=['Contacts handled incoming', 'Contacts transferred out internal'], \n",
    "                          aggfunc='first')  # Utiliza el primer valor si hay duplicados\n",
    "\n",
    "# Mostrar el DataFrame pivotado\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify and Complete Data\n",
    "\n",
    "Verify that all agents are present in each DataFrame. If an agent is missing, add a row with zeros for that agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_all_agents(df, agents_list):\n",
    "    \"\"\"\n",
    "    Ensure all agents are present in the DataFrame. Add missing agents with zero values and remove agents not in the list.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to check and update.\n",
    "    agents_list (list): The list of all agents.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The updated DataFrame with all agents.\n",
    "    \"\"\"\n",
    "    # Get the list of agents in the DataFrame\n",
    "    existing_agents = df.iloc[:, 0].tolist()\n",
    "    \n",
    "    # Find missing agents\n",
    "    missing_agents = [agent for agent in agents_list if agent not in existing_agents]\n",
    "    \n",
    "    # Add rows for missing agents with zero values\n",
    "    for agent in missing_agents:\n",
    "        zero_row = pd.DataFrame([[agent] + [0] * (df.shape[1] - 1)], columns=df.columns)\n",
    "        df = pd.concat([df, zero_row], ignore_index=True)\n",
    "    \n",
    "    # Remove agents not in the agents list\n",
    "    df = df[df.iloc[:, 0].isin(agents_list)]\n",
    "    \n",
    "    print(f\"Added {len(missing_agents)} missing agents and removed {len(existing_agents) - len(df)} agents not in the list.\")\n",
    "    return df\n",
    "\n",
    "# Apply the function to each DataFrame\n",
    "active_df = ensure_all_agents(active_df, agents_list)\n",
    "canceled_df = ensure_all_agents(canceled_df, agents_list)\n",
    "pending_signature_df = ensure_all_agents(pending_signature_df, agents_list)\n",
    "\n",
    "# Display the updated DataFrames\n",
    "print(\"Active DataFrame after ensuring all agents:\")\n",
    "display(active_df.head())\n",
    "\n",
    "print(\"Canceled DataFrame after ensuring all agents:\")\n",
    "display(canceled_df.head())\n",
    "\n",
    "print(\"Pending Signature DataFrame after ensuring all agents:\")\n",
    "display(pending_signature_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify and Complete Pivot Table Data\n",
    "\n",
    "Verify that all agents are present in the Pivot Table. If an agent is missing, add a row with zeros for that agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove extra agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def remove_extra_agents(pivot_df, agents_list):\n",
    "    \"\"\"\n",
    "    Remove agents from the pivot DataFrame that are not in the agents_list.\n",
    "    \n",
    "    Parameters:\n",
    "    pivot_df (pd.DataFrame): The pivoted DataFrame to update.\n",
    "    agents_list (list): The list of all agents to keep.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The updated pivot DataFrame with only the agents in agents_list.\n",
    "    \"\"\"\n",
    "    # Verificar si 'Agent' es un nivel de índice, si no, restaurarlo\n",
    "    if 'Agent' not in pivot_df.index.names:\n",
    "        pivot_df.index.names = ['Agent', 'StartInterval', 'EndInterval']\n",
    "    \n",
    "    # Obtener la cantidad inicial de agentes\n",
    "    initial_agents = len(pivot_df.index.get_level_values('Agent').unique())\n",
    "\n",
    "    # Filtrar el DataFrame para mantener solo los agentes que están en agents_list\n",
    "    pivot_df = pivot_df[pivot_df.index.get_level_values('Agent').isin(agents_list)]\n",
    "    \n",
    "    # Obtener la cantidad final de agentes\n",
    "    final_agents = len(pivot_df.index.get_level_values('Agent').unique())\n",
    "\n",
    "    # Calcular cuántos agentes se han eliminado\n",
    "    agents_removed = initial_agents - final_agents\n",
    "\n",
    "    print(f\"Removed {agents_removed} agents. Remaining agents: {final_agents}\")\n",
    "    return pivot_df\n",
    "\n",
    "def add_missing_agents(pivot_df, agents_list):\n",
    "    \"\"\"\n",
    "    Add missing agents to the pivot DataFrame with zero values for relevant columns.\n",
    "    \n",
    "    Parameters:\n",
    "    pivot_df (pd.DataFrame): The pivoted DataFrame to update.\n",
    "    agents_list (list): The list of all agents to ensure are present.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The updated pivot DataFrame with all agents.\n",
    "    \"\"\"\n",
    "    # Verificar si 'Agent' es un nivel de índice, si no, restaurarlo\n",
    "    if 'Agent' not in pivot_df.index.names:\n",
    "        pivot_df.index.names = ['Agent', 'StartInterval', 'EndInterval']\n",
    "\n",
    "    # Obtener la lista de agentes presentes en el DataFrame pivoteado\n",
    "    existing_agents = pivot_df.index.get_level_values('Agent').unique()\n",
    "\n",
    "    # Identificar agentes faltantes que están en la lista pero no en el pivot_df\n",
    "    missing_agents = [agent for agent in agents_list if agent not in existing_agents]\n",
    "\n",
    "    # Crear combinaciones de 'StartInterval' y 'EndInterval'\n",
    "    date_combinations = list(itertools.product(\n",
    "        pivot_df.index.get_level_values('StartInterval').unique(),\n",
    "        pivot_df.index.get_level_values('EndInterval').unique()\n",
    "    ))\n",
    "\n",
    "    # Añadir filas para los agentes faltantes con valores cero\n",
    "    for agent in missing_agents:\n",
    "        for start_interval, end_interval in date_combinations:\n",
    "            zero_row = pd.Series(\n",
    "                [0, 0],  # Valores para 'Contacts handled incoming' y 'Contacts transferred out internal'\n",
    "                index=pivot_df.columns,\n",
    "                name=(agent, start_interval, end_interval)\n",
    "            )\n",
    "            pivot_df = pd.concat([pivot_df, zero_row.to_frame().T])\n",
    "\n",
    "    print(f\"Added {len(missing_agents)} missing agents.\")\n",
    "    return pivot_df\n",
    "\n",
    "# Aplicar las funciones a la tabla pivoteada\n",
    "informe_df = remove_extra_agents(pivot_df, agents_list)\n",
    "informe_df = add_missing_agents(informe_df, agents_list)\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(\"Informe DataFrame after ensuring all agents:\")\n",
    "display(informe_df.head(55))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add extra agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_agents(pivot_df, agents_list):\n",
    "    \"\"\"\n",
    "    Add missing agents to the pivot DataFrame with zero values for relevant columns.\n",
    "    \n",
    "    Parameters:\n",
    "    pivot_df (pd.DataFrame): The pivoted DataFrame to update.\n",
    "    agents_list (list): The list of all agents to ensure are present.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The updated pivot DataFrame with all agents.\n",
    "    \"\"\"\n",
    "    # Verificar si 'Agent' es un nivel de índice, si no, restaurarlo\n",
    "    if 'Agent' not in pivot_df.index.names:\n",
    "        pivot_df.index.names = ['Agent', 'StartInterval', 'EndInterval']\n",
    "\n",
    "    # Obtener la lista de agentes presentes en el DataFrame pivoteado\n",
    "    existing_agents = pivot_df.index.get_level_values('Agent').unique()\n",
    "\n",
    "    # Identificar agentes faltantes que están en la lista pero no en el pivot_df\n",
    "    missing_agents = [agent for agent in agents_list if agent not in existing_agents]\n",
    "\n",
    "    # Crear combinaciones de 'StartInterval' y 'EndInterval'\n",
    "    date_combinations = list(itertools.product(\n",
    "        pivot_df.index.get_level_values('StartInterval').unique(),\n",
    "        pivot_df.index.get_level_values('EndInterval').unique()\n",
    "    ))\n",
    "\n",
    "    # Añadir filas para los agentes faltantes con valores cero\n",
    "    for agent in missing_agents:\n",
    "        for start_interval, end_interval in date_combinations:\n",
    "            zero_row = pd.Series(\n",
    "                [0, 0],  # Valores para 'Contacts handled incoming' y 'Contacts transferred out internal'\n",
    "                index=pivot_df.columns,\n",
    "                name=(agent, start_interval, end_interval)\n",
    "            )\n",
    "            pivot_df = pd.concat([pivot_df, zero_row.to_frame().T])\n",
    "\n",
    "    print(f\"Added {len(missing_agents)} missing agents.\")\n",
    "    return pivot_df\n",
    "\n",
    "# Aplicar las funciones a la tabla pivoteada\n",
    "informe_df = remove_extra_agents(pivot_df, agents_list)\n",
    "informe_df = add_missing_agents(informe_df, agents_list)\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(\"Informe DataFrame after ensuring all agents:\")\n",
    "display(informe_df.head(55))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Values to Emails\n",
    "\n",
    "Assign numerical values to each email and add them as a new column in the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping emails to their respective values\n",
    "email_values = {\n",
    "    'albaaraujo@originaltelecom.es': 1,\n",
    "    'albertocanto@originaltelecom.es': 2,\n",
    "    'albertosanchez@originaltelecom.es': 3,\n",
    "    'anasanchez@originaltelecom.es': 4,\n",
    "    'antonio.reina@originaltelecom.es': 5,\n",
    "    'azahara.garcia@originaltelecom.es': 6,\n",
    "    'beatriz.gomez@originaltelecom.es': 7,\n",
    "    'carmen.cornejo@originaltelecom.es': 8,\n",
    "    'carolinafuentes@originaltelecom.es': 9,\n",
    "    'cesar.arnaldo@originaltelecom.es': 10,\n",
    "    'david.molero@originaltelecom.es': 11,\n",
    "    'elenaborrero@originaltelecom.es': 12,\n",
    "    'estefania.panea@originaltelecom.es': 13,\n",
    "    'francisco.perdomo@originaltelecom.es': 14,\n",
    "    'gonzalofalcon@originaltelecom.es': 15,\n",
    "    'guillermo.hurtado@originaltelecom.es': 16,\n",
    "    'irati.izaguirre@originaltelecom.es': 17,\n",
    "    'ivan.barroso@originaltelecom.es': 18,\n",
    "    'laura.eguens@originaltelecom.es': 19,\n",
    "    'lailasetati@originaltelecom.es': 20,\n",
    "    'leonor.lopez@originaltelecom.es': 21,\n",
    "    'dolores.cortes@originaltelecom.es': 22,\n",
    "    'manuelvaldes@originaltelecom.es': 23,\n",
    "    'manuelventura@originaltelecom.es': 24,\n",
    "    'mar.aguila@originaltelecom.es': 25,\n",
    "    'mariangeles.bueso@originaltelecom.es': 26,\n",
    "    'mariaarroyo@originaltelecom.es': 27,\n",
    "    'maria.torres@originaltelecom.es': 28,\n",
    "    'marta.dorado@originaltelecom.es': 29,\n",
    "    'mauricio.pozo@originaltelecom.es': 30,\n",
    "    'miguel.segura@originaltelecom.es': 31,\n",
    "    'miriam.rodriguez@originaltelecom.es': 32,\n",
    "    'mar.marchena@originaltelecom.es': 33,\n",
    "    'natividad.sanchez@originaltelecom.es': 34,\n",
    "    'nereacerezo@originaltelecom.es': 35,\n",
    "    'oscar.rivilla@originaltelecom.es': 36,\n",
    "    'patricia.rios@originaltelecom.es': 37,\n",
    "    'paulavilla@originaltelecom.es': 38,\n",
    "    'pilar.deval@originaltelecom.es': 39,\n",
    "    'sara.elkhelyfy@originaltelecom.es': 40,\n",
    "    'sergio.vazquez@originaltelecom.es': 41,\n",
    "    'yicel.patricia@originaltelecom.es': 42,\n",
    "    'yzabelly.gomes@originaltelecom.es': 43\n",
    "}\n",
    "\n",
    "# Add a new column to each DataFrame with the email values\n",
    "def add_email_values(df, email_values):\n",
    "    df['email_value'] = df.iloc[:, 0].map(email_values)\n",
    "    return df\n",
    "\n",
    "# Apply the function to each DataFrame\n",
    "active_df = add_email_values(active_df, email_values)\n",
    "canceled_df = add_email_values(canceled_df, email_values)\n",
    "pending_signature_df = add_email_values(pending_signature_df, email_values)\n",
    "\n",
    "# Display the updated DataFrames with the new 'email_value' column\n",
    "print(\"Active DataFrame with email values:\")\n",
    "display(active_df.head())\n",
    "\n",
    "print(\"Canceled DataFrame with email values:\")\n",
    "display(canceled_df.head())\n",
    "\n",
    "print(\"Pending Signature DataFrame with email values:\")\n",
    "display(pending_signature_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort DataFrames by Email Values\n",
    "\n",
    "Sort the DataFrames based on the numerical values assigned to the emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort each DataFrame by the 'email_value' column\n",
    "def sort_by_email_value(df):\n",
    "    df = df.sort_values(by='email_value')\n",
    "    return df\n",
    "\n",
    "# Apply the sorting function to each DataFrame\n",
    "active_df = sort_by_email_value(active_df)\n",
    "canceled_df = sort_by_email_value(canceled_df)\n",
    "pending_signature_df = sort_by_email_value(pending_signature_df)\n",
    "\n",
    "# Display the sorted DataFrames\n",
    "print(\"Sorted Active DataFrame:\")\n",
    "display(active_df.head())  # Displaying first 20 rows for testing\n",
    "\n",
    "print(\"Sorted Canceled DataFrame:\")\n",
    "display(canceled_df.head())  # Displaying first 20 rows for testing\n",
    "\n",
    "print(\"Sorted Pending Signature DataFrame:\")\n",
    "display(pending_signature_df.head())  # Displaying first 20 rows for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove 'email_value' Column\n",
    "\n",
    "After sorting the DataFrames based on the email values, the 'email_value' column should be removed to prevent interference with further calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove the 'email_value' column\n",
    "def remove_email_value_column(df):\n",
    "    if 'email_value' in df.columns:\n",
    "        df = df.drop(columns=['email_value'])\n",
    "    return df\n",
    "\n",
    "# Apply the function to each DataFrame\n",
    "active_df = remove_email_value_column(active_df)\n",
    "canceled_df = remove_email_value_column(canceled_df)\n",
    "pending_signature_df = remove_email_value_column(pending_signature_df)\n",
    "\n",
    "# Display the updated DataFrames without the 'email_value' column\n",
    "print(\"Active DataFrame after removing 'email_value' column:\")\n",
    "display(active_df.head())\n",
    "\n",
    "print(\"Canceled DataFrame after removing 'email_value' column:\")\n",
    "display(canceled_df.head())\n",
    "\n",
    "print(\"Pending Signature DataFrame after removing 'email_value' column:\")\n",
    "display(pending_signature_df.head())\n",
    "\n",
    "column_values = active_df.iloc[:, 0].tolist()\n",
    "print(\"Values from the second column of active_df:\")\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove agents from the three sheets. Later will have to be adequated in the previous piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de agentes a eliminar\n",
    "agents_to_remove = ['mar.aguila@originaltelecom.es', 'formacion4@originaltelecom.es', 'formacion10@originaltelecom.es', 'formacion3@originaltelecom.es']\n",
    "\n",
    "# Eliminar filas donde la primera columna contiene alguno de los agentes en la lista\n",
    "active_df = active_df[~active_df.iloc[:, 0].isin(agents_to_remove)]\n",
    "canceled_df = canceled_df[~canceled_df.iloc[:, 0].isin(agents_to_remove)]\n",
    "pending_signature_df = pending_signature_df[~pending_signature_df.iloc[:, 0].isin(agents_to_remove)]\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(\"Active DataFrame after removing specific agents:\")\n",
    "display(active_df.head())\n",
    "\n",
    "column_values = active_df.iloc[:, 0].tolist()\n",
    "print(\"Values from the second column of active_df:\")\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Active DataFrame\n",
    "\n",
    "Sum all numeric values in each row, divide the result by 2, and store the final values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sum of numeric values in each row, divided by 2\n",
    "active_sums = active_df.iloc[:, 1:].sum(axis=1) / 2  # Assuming the first column is not numeric\n",
    "print(\"Calculated sums for 'Active' DataFrame:\")\n",
    "print(active_sums.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update finalFile Excel Sheet\n",
    "\n",
    "Update the \"finalFile\" Excel sheet with the calculated values from the Active DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "# Path to the final file\n",
    "final_file_path ='/workspaces/Finetwork-Automation/inbound/OBJETIVO_CALL_INB_AGOSTO_24.xlsx'\n",
    "sheet_name = 'GLOBAL AGOSTO'  # Change this to the correct sheet name\n",
    "\n",
    "def update_final_file(file_path, sheet_name, values):\n",
    "    # Load the workbook and select the sheet\n",
    "    workbook = load_workbook(filename=file_path)\n",
    "    sheet = workbook[sheet_name]\n",
    "    \n",
    "    # Start updating from row 3 in column F (6th column)\n",
    "    start_row = 3\n",
    "    column = 10  # Column J\n",
    "    \n",
    "    for i, value in enumerate(values, start=start_row):\n",
    "        sheet.cell(row=i, column=column, value=value)\n",
    "    \n",
    "    # Save the workbook\n",
    "    workbook.save(file_path)\n",
    "    print(f\"Updated {len(values)} rows in '{sheet_name}' sheet of '{file_path}'.\")\n",
    "\n",
    "# Update the final file with the calculated sums\n",
    "update_final_file(final_file_path, sheet_name, active_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Canceled DataFrame\n",
    "\n",
    "Sum all numeric values in each row, divide the result by 2, and store the final values in column N starting from row 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sum of numeric values in each row, divided by 2 for 'Canceled' DataFrame\n",
    "canceled_sums = canceled_df.iloc[:, 1:].sum(axis=1) / 2  # Assuming the first column is not numeric\n",
    "print(\"Calculated sums for 'Canceled' DataFrame:\")\n",
    "print(canceled_sums.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update finalFile Excel Sheet with Canceled Data\n",
    "\n",
    "Update the \"finalFile\" Excel sheet with the calculated values from the Canceled DataFrame in column N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_final_file_canceled(file_path, sheet_name, values):\n",
    "    # Load the workbook and select the sheet\n",
    "    workbook = load_workbook(filename=file_path)\n",
    "    sheet = workbook[sheet_name]\n",
    "    \n",
    "    # Start updating from row 3 in column N (14th column)\n",
    "    start_row = 3\n",
    "    column = 11  # Column K\n",
    "    \n",
    "    for i, value in enumerate(values, start=start_row):\n",
    "        sheet.cell(row=i, column=column, value=value)\n",
    "    \n",
    "    # Save the workbook\n",
    "    workbook.save(file_path)\n",
    "    print(f\"Updated {len(values)} rows in '{sheet_name}' sheet of '{file_path}' with Canceled data.\")\n",
    "\n",
    "# Update the final file with the calculated sums for Canceled\n",
    "update_final_file_canceled(final_file_path, sheet_name, canceled_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Pending Signature DataFrame\n",
    "\n",
    "Sum all numeric values in each row, divide the result by 2, and store the final values in column Q starting from row 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sum of numeric values in each row, divided by 2 for 'Pending Signature' DataFrame\n",
    "pending_signature_sums = pending_signature_df.iloc[:, 1:].sum(axis=1) / 2  # Assuming the first column is not numeric\n",
    "print(\"Calculated sums for 'Pending Signature' DataFrame:\")\n",
    "print(pending_signature_sums.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update finalFile Excel Sheet with Pending Signature Data\n",
    "\n",
    "Update the \"finalFile\" Excel sheet with the calculated values from the Pending Signature DataFrame in column Q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_final_file_pending_signature(file_path, sheet_name, values):\n",
    "    # Load the workbook and select the sheet\n",
    "    workbook = load_workbook(filename=file_path)\n",
    "    sheet = workbook[sheet_name]\n",
    "    \n",
    "    # Start updating from row 3 in column Q (17th column)\n",
    "    start_row = 3\n",
    "    column = 12  # Column L\n",
    "    \n",
    "    for i, value in enumerate(values, start=start_row):\n",
    "        sheet.cell(row=i, column=column, value=value)\n",
    "    \n",
    "    # Save the workbook\n",
    "    workbook.save(file_path)\n",
    "    print(f\"Updated {len(values)} rows in '{sheet_name}' sheet of '{file_path}' with Pending Signature data.\")\n",
    "\n",
    "# Update the final file with the calculated sums for Pending Signature\n",
    "update_final_file_pending_signature(final_file_path, sheet_name, pending_signature_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update finalFile Excel Sheet with Informe Data\n",
    "\n",
    "Update the \"finalFile\" Excel sheet with the raw values from the Informe DataFrame in column Q."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Useful Columns for Active DataFrame\n",
    "\n",
    "Determine the range of columns that will be used for the Active DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the range of columns for Active DataFrame\n",
    "active_usecols = active_df.columns[:-1]  # Exclude the last column\n",
    "print(\"Active DataFrame Useful Columns:\")\n",
    "print(active_usecols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Useful Columns for Canceled DataFrame\n",
    "\n",
    "Determine the range of columns that will be used for the Canceled DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the range of columns for Canceled DataFrame\n",
    "canceled_usecols = canceled_df.columns[:-1]  # Exclude the last column\n",
    "print(\"Canceled DataFrame Useful Columns:\")\n",
    "print(canceled_usecols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Useful Columns for Pending Signature DataFrame\n",
    "\n",
    "Determine the range of columns that will be used for the Pending Signature DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the range of columns for Pending Signature DataFrame\n",
    "pending_signature_usecols = pending_signature_df.columns[:-1]  # Exclude the last column\n",
    "print(\"Pending Signature DataFrame Useful Columns:\")\n",
    "print(pending_signature_usecols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Diario Agosto Sheet with Active DataFrame\n",
    "\n",
    "For each useful column in the Active DataFrame, update the corresponding column in the \"DIARIO AGOSTO\" sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_diario_agosto_with_last_column(df, file_path):\n",
    "    \"\"\"\n",
    "    Update the \"DIARIO AGOSTO\" sheet with values from the last column of the Active DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The Active DataFrame.\n",
    "    file_path (str): Path to the Excel file.\n",
    "    \"\"\"\n",
    "    workbook = load_workbook(filename=file_path)\n",
    "    sheet = workbook['DIARIO AGOSTO']\n",
    "    \n",
    "    # Identify the last and penultimate columns in the DataFrame\n",
    "    last_column_name = df.columns[-2]\n",
    "    penultimate_column_index = len(df.columns) - 2  # Get the index of the penultimate column\n",
    "    \n",
    "    # Define the column mappings: Active DataFrame -> DIARIO AGOSTO\n",
    "    column_mappings = {\n",
    "        2: 'C',   # Assuming 'B' is the first column\n",
    "        3: 'H',   # Assuming 'C' is the second column\n",
    "        4: 'M',   # Assuming 'D' is the third column\n",
    "        5: 'R',   # Assuming 'E' is the fourth column\n",
    "        6: 'AB',  # Assuming 'F' is the fifth column\n",
    "        7: 'AG',\n",
    "        8: 'AL',\n",
    "        9: 'AQ',\n",
    "        10: 'AV',\n",
    "        11: 'BA',\n",
    "        12: 'BF',\n",
    "        13: 'BK',\n",
    "        14: 'BP',\n",
    "        15: 'BU',\n",
    "        16: 'BZ',\n",
    "        17: 'CE',\n",
    "        18: 'CJ',\n",
    "        19: 'CO',\n",
    "        20: 'CT',\n",
    "        21: 'CY',\n",
    "        22: 'DD',\n",
    "        23: 'DI',\n",
    "        24: 'DN',\n",
    "        25: 'DS',\n",
    "        26: 'DX',\n",
    "        27: 'EC',\n",
    "        28: 'EH',\n",
    "        29: 'EM',\n",
    "        30: 'ER',\n",
    "        31: 'EW'\n",
    "    }\n",
    "    \n",
    "    # Determine the target column based on the penultimate column index\n",
    "    target_column = column_mappings.get(penultimate_column_index, 'EW')  # Default to 'EW' if index not found\n",
    "    \n",
    "    # Update the Excel sheet with values from the last column of the DataFrame\n",
    "    for row_idx, value in enumerate(df[last_column_name], start=4):  # Assuming Excel updates start at row 4\n",
    "        sheet[f'{target_column}{row_idx}'] = value\n",
    "    \n",
    "    workbook.save(file_path)\n",
    "    print(f\"Updated DIARIO AGOSTO sheet with the last column '{last_column_name}' from Active DataFrame.\")\n",
    "\n",
    "# Update the Diario Agosto sheet with the last column of the Active DataFrame\n",
    "update_diario_agosto_with_last_column(active_df, final_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Diario Agosto Sheet with Canceled DataFrame\n",
    "\n",
    "For each useful column in the Canceled DataFrame, update the corresponding column in the \"DIARIO AGOSTO\" sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_diario_agosto_with_last_column_canceled(df, file_path):\n",
    "    \"\"\"\n",
    "    Update the \"DIARIO AGOSTO\" sheet with values from the last column of the Canceled DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The Canceled DataFrame.\n",
    "    file_path (str): Path to the Excel file.\n",
    "    \"\"\"\n",
    "    workbook = load_workbook(filename=file_path)\n",
    "    sheet = workbook['DIARIO AGOSTO']\n",
    "    \n",
    "    # Identify the last and penultimate columns in the DataFrame\n",
    "    last_column_name = df.columns[-2]\n",
    "    penultimate_column_index = len(df.columns) - 2  # Get the index of the penultimate column\n",
    "    \n",
    "    # Define the column mappings: Canceled DataFrame -> DIARIO AGOSTO\n",
    "    column_mappings = {\n",
    "        2: 'D',   \n",
    "        3: 'I',   \n",
    "        4: 'N',   \n",
    "        5: 'S',   \n",
    "        6: 'AC',  \n",
    "        7: 'AH',\n",
    "        8: 'AM',\n",
    "        9: 'AR',\n",
    "        10: 'AW',\n",
    "        11: 'BB',\n",
    "        12: 'BG',\n",
    "        13: 'BL',\n",
    "        14: 'BQ',\n",
    "        15: 'BV',\n",
    "        16: 'CA',\n",
    "        17: 'CF',\n",
    "        18: 'CK',\n",
    "        19: 'CP',\n",
    "        20: 'CU',\n",
    "        21: 'CZ',\n",
    "        22: 'DE',\n",
    "        23: 'DJ',\n",
    "        24: 'DO',\n",
    "        25: 'DT',\n",
    "        26: 'DY',\n",
    "        27: 'ED',\n",
    "        28: 'EI',\n",
    "        29: 'EN',\n",
    "        30: 'ES',\n",
    "        31: 'EX'\n",
    "    }\n",
    "    \n",
    "    # Determine the target column based on the penultimate column index\n",
    "    target_column = column_mappings.get(penultimate_column_index, 'EW')  # Default to 'EW' if index not found\n",
    "    \n",
    "    # Update the Excel sheet with values from the last column of the DataFrame\n",
    "    for row_idx, value in enumerate(df[last_column_name], start=4):  # Assuming Excel updates start at row 4\n",
    "        sheet[f'{target_column}{row_idx}'] = value\n",
    "    \n",
    "    workbook.save(file_path)\n",
    "    print(f\"Updated DIARIO AGOSTO sheet with the last column '{last_column_name}' from Canceled DataFrame.\")\n",
    "\n",
    "# Update the Diario Agosto sheet with the last column of the Canceled DataFrame\n",
    "update_diario_agosto_with_last_column_canceled(canceled_df, final_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Diario Agosto Sheet with Pending Signature DataFrame\n",
    "\n",
    "For each useful column in the Pending Signature DataFrame, update the corresponding column in the \"DIARIO AGOSTO\" sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_diario_agosto_with_last_column_pending_signature(df, file_path):\n",
    "    \"\"\"\n",
    "    Update the \"DIARIO AGOSTO\" sheet with values from the last column of the Pending Signature DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The Pending Signature DataFrame.\n",
    "    file_path (str): Path to the Excel file.\n",
    "    \"\"\"\n",
    "    workbook = load_workbook(filename=file_path)\n",
    "    sheet = workbook['DIARIO AGOSTO']\n",
    "    \n",
    "    # Identify the last and penultimate columns in the DataFrame\n",
    "    last_column_name = df.columns[-2]\n",
    "    penultimate_column_index = len(df.columns) - 2  # Get the index of the penultimate column\n",
    "    \n",
    "    # Define the column mappings: Pending Signature DataFrame -> DIARIO AGOSTO\n",
    "    column_mappings = {\n",
    "        2: 'E',   # Adjusted to the next column\n",
    "        3: 'J',   \n",
    "        4: 'O',   \n",
    "        5: 'T',   \n",
    "        6: 'AD',  \n",
    "        7: 'AI',\n",
    "        8: 'AN',\n",
    "        9: 'AS',\n",
    "        10: 'AX',\n",
    "        11: 'BC',\n",
    "        12: 'BH',\n",
    "        13: 'BM',\n",
    "        14: 'BR',\n",
    "        15: 'BW',\n",
    "        16: 'CB',\n",
    "        17: 'CG',\n",
    "        18: 'CL',\n",
    "        19: 'CQ',\n",
    "        20: 'CV',\n",
    "        21: 'DA',\n",
    "        22: 'DF',\n",
    "        23: 'DK',\n",
    "        24: 'DP',\n",
    "        25: 'DU',\n",
    "        26: 'DZ',\n",
    "        27: 'EE',\n",
    "        28: 'EJ',\n",
    "        29: 'EO',\n",
    "        30: 'ET',\n",
    "        31: 'EY'\n",
    "    }\n",
    "    \n",
    "    # Determine the target column based on the penultimate column index\n",
    "    target_column = column_mappings.get(penultimate_column_index, 'EY')  # Default to 'EY' if index not found\n",
    "    \n",
    "    # Update the Excel sheet with values from the last column of the DataFrame\n",
    "    for row_idx, value in enumerate(df[last_column_name], start=4):  # Assuming Excel updates start at row 4\n",
    "        sheet[f'{target_column}{row_idx}'] = value\n",
    "    \n",
    "    workbook.save(file_path)\n",
    "    print(f\"Updated DIARIO AGOSTO sheet with the last column '{last_column_name}' from Pending Signature DataFrame.\")\n",
    "\n",
    "# Update the Diario Agosto sheet with the last column of the Pending Signature DataFrame\n",
    "update_diario_agosto_with_last_column_pending_signature(pending_signature_df, final_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Diario Agosto Sheet with Informe DataFrame\n",
    "\n",
    "For each useful column in the Informe DataFrame, update the corresponding column in the \"DIARIO AGOSTO\" sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
